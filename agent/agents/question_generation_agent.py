#!/usr/bin/env python3
"""
æ”¹è¿›çš„é¢˜ç›®ç”ŸæˆAgent - åŸºäºåˆ†å±‚å­¦ä¹ ç†è®ºå’Œè®¤çŸ¥è´Ÿè·ç†è®º
"""

import os
import sys
import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from langchain.tools import tool
from langgraph.prebuilt import create_react_agent
from langchain_community.chat_models import ChatTongyi

# å¯¼å…¥å·¥å…·ç±»
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from utils import DatabaseManager, PDFTextExtractor
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ°utilsæ¨¡å—ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")
    DatabaseManager = None
    PDFTextExtractor = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… å·²åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡")
except ImportError:
    print("âš ï¸  æœªå®‰è£…python-dotenvåŒ…ï¼Œæ— æ³•åŠ è½½.envæ–‡ä»¶")

# æ£€æŸ¥APIå¯†é’¥
api_key = os.getenv("DASHSCOPE_API_KEY")
if not api_key:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ°DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    print("   è¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ : DASHSCOPE_API_KEY=your-api-key")
else:
    print("âœ… æ‰¾åˆ°DASHSCOPE_API_KEY")

# ========== ç¬¬ä¸€å±‚ï¼šçŸ¥è¯†ç»“æ„åˆ†æå±‚ ==========

@tool
def extract_core_concepts(paper_content: str, paper_title: str) -> str:
    """
    ä»è®ºæ–‡ä¸­æå–æ ¸å¿ƒæ¦‚å¿µåŠå…¶å®šä¹‰
    
    Args:
        paper_content (str): è®ºæ–‡å®Œæ•´å†…å®¹
        paper_title (str): è®ºæ–‡æ ‡é¢˜
        
    Returns:
        str: æ ¸å¿ƒæ¦‚å¿µJSONæ ¼å¼ {"concepts": [{"name": "", "definition": "", "importance": 1-5}]}
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.3)
        
    prompt = f"""
åˆ†æä»¥ä¸‹è®ºæ–‡ï¼Œæå–5-10ä¸ªæœ€æ ¸å¿ƒçš„æ¦‚å¿µï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{paper_title}
è®ºæ–‡å†…å®¹ï¼š
{paper_content[:3000]}

è¦æ±‚ï¼š
1. æå–æœ€åŸºç¡€ã€æœ€æ ¸å¿ƒçš„æ¦‚å¿µ
2. ç»™å‡ºç®€æ´çš„å®šä¹‰ï¼ˆä¸è¶…è¿‡100å­—ï¼‰
3. æŒ‰é‡è¦æ€§æ’åºï¼ˆ1-5åˆ†ï¼Œ5åˆ†æœ€é‡è¦ï¼‰
4. ç¡®ä¿æ¦‚å¿µä¹‹é—´æœ‰é€»è¾‘å…³è”

è¿”å›JSONæ ¼å¼ï¼š
{{
    "concepts": [
        {{
            "name": "æ¦‚å¿µåç§°",
            "definition": "æ¦‚å¿µå®šä¹‰", 
            "importance": 5,
            "category": "åŸºç¡€ç†è®º/æ–¹æ³•æŠ€æœ¯/åº”ç”¨å®è·µ"
        }}
    ]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def analyze_knowledge_dependencies(concepts_json: str) -> str:
    """
    åˆ†æçŸ¥è¯†ç‚¹ä¹‹é—´çš„ä¾èµ–å…³ç³»
    
    Args:
        concepts_json (str): æ ¸å¿ƒæ¦‚å¿µJSON
        
    Returns:
        str: ä¾èµ–å…³ç³»JSONæ ¼å¼
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.3)
    
    prompt = f"""
åˆ†æä»¥ä¸‹æ¦‚å¿µä¹‹é—´çš„å­¦ä¹ ä¾èµ–å…³ç³»ï¼š

æ¦‚å¿µåˆ—è¡¨ï¼š
{concepts_json}

è¦æ±‚ï¼š
1. ç¡®å®šæ¦‚å¿µçš„å­¦ä¹ é¡ºåºï¼ˆå“ªäº›æ˜¯å‰ç½®æ¦‚å¿µï¼‰
2. æ ‡è¯†æ¦‚å¿µä¹‹é—´çš„å¼ºä¾èµ–å’Œå¼±ä¾èµ–å…³ç³»
3. å°†æ¦‚å¿µåˆ†ä¸ºä¸åŒçš„å­¦ä¹ å±‚çº§

è¿”å›JSONæ ¼å¼ï¼š
{{
    "learning_sequence": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", ...],
    "dependencies": [
        {{
            "prerequisite": "å‰ç½®æ¦‚å¿µ",
            "dependent": "ä¾èµ–æ¦‚å¿µ", 
            "strength": "strong/weak"
        }}
    ],
    "levels": {{
        "foundation": ["åŸºç¡€æ¦‚å¿µ"],
        "intermediate": ["ä¸­çº§æ¦‚å¿µ"],
        "advanced": ["é«˜çº§æ¦‚å¿µ"]
    }}
}}
"""
        
    response = model.invoke(prompt)
    return response.content

@tool
def classify_cognitive_levels(concepts_json: str, dependencies_json: str) -> str:
    """
    æŒ‰è®¤çŸ¥å±‚æ¬¡å¯¹æ¦‚å¿µè¿›è¡Œåˆ†ç±»ï¼ˆå¸ƒé²å§†åˆ†ç±»æ³•ï¼‰
    
    Args:
        concepts_json (str): æ ¸å¿ƒæ¦‚å¿µJSON
        dependencies_json (str): ä¾èµ–å…³ç³»JSON
        
    Returns:
        str: è®¤çŸ¥å±‚æ¬¡åˆ†ç±»JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.3)
        
    prompt = f"""
åŸºäºå¸ƒé²å§†è®¤çŸ¥åˆ†ç±»æ³•ï¼Œå¯¹æ¦‚å¿µè¿›è¡Œå±‚æ¬¡åˆ†ç±»ï¼š

æ¦‚å¿µï¼š{concepts_json}
ä¾èµ–å…³ç³»ï¼š{dependencies_json}

è®¤çŸ¥å±‚æ¬¡ï¼š
1. è®°å¿†ï¼ˆRememberï¼‰- åŸºç¡€äº‹å®å’Œå®šä¹‰
2. ç†è§£ï¼ˆUnderstandï¼‰- æ¦‚å¿µè§£é‡Šå’Œå…³ç³»
3. åº”ç”¨ï¼ˆApplyï¼‰- å®é™…é—®é¢˜è§£å†³
4. åˆ†æï¼ˆAnalyzeï¼‰- å¤æ‚å…³ç³»åˆ†æ
5. ç»¼åˆï¼ˆSynthesizeï¼‰- åˆ›æ–°æ•´åˆ
6. è¯„ä»·ï¼ˆEvaluateï¼‰- æ‰¹åˆ¤æ€§æ€ç»´

è¿”å›JSONæ ¼å¼ï¼š
{{
    "cognitive_mapping": {{
        "remember": ["åŸºç¡€æ¦‚å¿µå®šä¹‰"],
        "understand": ["æ¦‚å¿µåŸç†è§£é‡Š"],
        "apply": ["å®é™…åº”ç”¨åœºæ™¯"],
        "analyze": ["å¤æ‚å…³ç³»åˆ†æ"],
        "synthesize": ["åˆ›æ–°æ•´åˆ"], 
        "evaluate": ["æ‰¹åˆ¤è¯„ä»·"]
    }}
}}
"""
        
    response = model.invoke(prompt)
    return response.content

# ========== ç¬¬äºŒå±‚ï¼šæ¦‚å¿µé”šå®šå±‚ ==========

@tool
def map_existing_knowledge(concept_name: str, concept_definition: str) -> str:
    """
    å°†æ–°æ¦‚å¿µæ˜ å°„åˆ°å­¦ä¹ è€…å·²æœ‰çš„å¸¸è¯†çŸ¥è¯†
    
    Args:
        concept_name (str): æ¦‚å¿µåç§°
        concept_definition (str): æ¦‚å¿µå®šä¹‰
        
    Returns:
        str: çŸ¥è¯†æ˜ å°„JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.7)
    
    prompt = f"""
å°†å­¦æœ¯æ¦‚å¿µè¿æ¥åˆ°æ—¥å¸¸ç”Ÿæ´»å¸¸è¯†ï¼š

æ¦‚å¿µï¼š{concept_name}
å®šä¹‰ï¼š{concept_definition}

è¦æ±‚ï¼š
1. æ‰¾å‡º3-5ä¸ªæ—¥å¸¸ç”Ÿæ´»ä¸­çš„ç›¸ä¼¼ä¾‹å­
2. å»ºç«‹ä»ç†Ÿæ‚‰åˆ°é™Œç”Ÿçš„çŸ¥è¯†æ¡¥æ¢
3. ç”¨é€šä¿—è¯­è¨€é‡æ–°è§£é‡Šæ¦‚å¿µ

è¿”å›JSONæ ¼å¼ï¼š
{{
    "everyday_examples": ["æ—¥å¸¸ä¾‹å­1", "æ—¥å¸¸ä¾‹å­2"],
    "analogies": ["ç±»æ¯”1", "ç±»æ¯”2"],
    "simplified_explanation": "é€šä¿—åŒ–è§£é‡Š",
    "knowledge_bridge": "ä»å·²çŸ¥åˆ°æœªçŸ¥çš„è¿æ¥è¿‡ç¨‹"
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def generate_concept_analogies(concept_name: str, target_audience: str = "æœ¬ç§‘ç”Ÿ") -> str:
    """
    ä¸ºå¤æ‚æ¦‚å¿µç”Ÿæˆç±»æ¯”å’Œéšå–»
    
    Args:
        concept_name (str): æ¦‚å¿µåç§°
        target_audience (str): ç›®æ ‡å—ä¼—
        
    Returns:
        str: ç±»æ¯”éšå–»JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.8)
        
    prompt = f"""
ä¸ºå¤æ‚æ¦‚å¿µåˆ›é€ ç”ŸåŠ¨çš„ç±»æ¯”å’Œéšå–»ï¼š

æ¦‚å¿µï¼š{concept_name}
ç›®æ ‡å—ä¼—ï¼š{target_audience}

è¦æ±‚ï¼š
1. åˆ›é€ 2-3ä¸ªç”ŸåŠ¨çš„ç±»æ¯”
2. ç¡®ä¿ç±»æ¯”å‡†ç¡®ä¸”æ˜“äºç†è§£
3. è§£é‡Šç±»æ¯”çš„å¯¹åº”å…³ç³»

è¿”å›JSONæ ¼å¼ï¼š
{{
    "analogies": [
        {{
            "analogy": "ç±»æ¯”æè¿°",
            "explanation": "ç±»æ¯”è§£é‡Š",
            "correspondence": "å¯¹åº”å…³ç³»è¯´æ˜"
        }}
    ],
    "metaphors": ["éšå–»1", "éšå–»2"]
}}
"""
        
    response = model.invoke(prompt)
    return response.content

# ========== ç¬¬ä¸‰å±‚ï¼šåˆ†å±‚é¢˜ç›®ç”Ÿæˆå±‚ ==========

@tool
def generate_memory_level_questions(concept_name: str, definition: str, knowledge_mapping: str) -> str:
    """
    ç”Ÿæˆè®°å¿†å±‚æ¬¡é¢˜ç›®ï¼ˆåŸºç¡€æ¦‚å¿µè¯†åˆ«ï¼‰
    
    Args:
        concept_name (str): æ¦‚å¿µåç§°
        definition (str): æ¦‚å¿µå®šä¹‰
        knowledge_mapping (str): çŸ¥è¯†æ˜ å°„JSON
        
    Returns:
        str: è®°å¿†å±‚é¢˜ç›®JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.5)
    
    prompt = f"""
åŸºäºæ¦‚å¿µç”Ÿæˆè®°å¿†å±‚æ¬¡çš„å­¦ä¹ é¢˜ç›®ï¼š

æ¦‚å¿µï¼š{concept_name}
å®šä¹‰ï¼š{definition}
çŸ¥è¯†æ˜ å°„ï¼š{knowledge_mapping}

è®°å¿†å±‚æ¬¡è¦æ±‚ï¼š
- æµ‹è¯•åŸºç¡€äº‹å®è®°å¿†
- æ¦‚å¿µå®šä¹‰è¯†åˆ«
- å…³é”®æœ¯è¯­ç†è§£
- ä½¿ç”¨ç®€å•ç›´æ¥çš„è¯­è¨€

ç”Ÿæˆ2é“ä¸åŒç±»å‹çš„é¢˜ç›®ï¼š
1. é€‰æ‹©é¢˜ï¼ˆæ¦‚å¿µå®šä¹‰åŒ¹é…ï¼‰
2. å¡«ç©ºé¢˜ï¼ˆå…³é”®è¯å¡«ç©ºï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{{
    "questions": [
        {{
            "level": "memory",
            "type": "multiple_choice",
            "stem": "é¢˜å¹²",
            "options": ["A. é€‰é¡¹1", "B. é€‰é¡¹2", "C. é€‰é¡¹3", "D. é€‰é¡¹4"],
            "correct_answer": "A",
            "explanation": "ç­”æ¡ˆè§£é‡Š",
            "cognitive_focus": "æµ‹è¯•çš„è®¤çŸ¥è¦ç‚¹"
        }}
    ]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def generate_understanding_level_questions(concept_name: str, analogies: str, dependencies: str) -> str:
    """
    ç”Ÿæˆç†è§£å±‚æ¬¡é¢˜ç›®ï¼ˆæ¦‚å¿µå…³ç³»å’ŒåŸç†ï¼‰
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.6)
    
    prompt = f"""
ç”Ÿæˆç†è§£å±‚æ¬¡çš„é¢˜ç›®ï¼š

æ¦‚å¿µï¼š{concept_name}
ç±»æ¯”ï¼š{analogies}
ä¾èµ–å…³ç³»ï¼š{dependencies}

ç†è§£å±‚æ¬¡è¦æ±‚ï¼š
- æµ‹è¯•æ¦‚å¿µä¹‹é—´çš„å…³ç³»
- åŸç†çš„è§£é‡Šèƒ½åŠ›
- ä½¿ç”¨ç±»æ¯”å¸®åŠ©ç†è§£
- åŒ…å«"ä¸ºä»€ä¹ˆ"ç±»å‹çš„é—®é¢˜

ç”Ÿæˆ2-3é“é¢˜ç›®ï¼ŒåŒ…å«ï¼š
1. è§£é‡Šé¢˜ï¼ˆæ¦‚å¿µåŸç†è§£é‡Šï¼‰
2. å…³ç³»é¢˜ï¼ˆæ¦‚å¿µé—´å…³ç³»ï¼‰
3. ç±»æ¯”é¢˜ï¼ˆä½¿ç”¨ç±»æ¯”ç†è§£ï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{{
    "questions": [
        {{
            "level": "understanding",
            "type": "short_answer",
            "stem": "é¢˜å¹²",
            "correct_answer": "æ­£ç¡®ç­”æ¡ˆ",
            "explanation": "ç­”æ¡ˆè§£é‡Š",
            "cognitive_focus": "æµ‹è¯•çš„è®¤çŸ¥è¦ç‚¹"
        }}
    ]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def generate_application_level_questions(concept_name: str, real_world_examples: str) -> str:
    """
    ç”Ÿæˆåº”ç”¨å±‚æ¬¡é¢˜ç›®ï¼ˆå®é™…é—®é¢˜è§£å†³ï¼‰
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.6)
    
    prompt = f"""
ç”Ÿæˆåº”ç”¨å±‚æ¬¡çš„é¢˜ç›®ï¼š

æ¦‚å¿µï¼š{concept_name}
å®é™…ä¾‹å­ï¼š{real_world_examples}

åº”ç”¨å±‚æ¬¡è¦æ±‚ï¼š
- æµ‹è¯•åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨èƒ½åŠ›
- é—®é¢˜è§£å†³æŠ€èƒ½
- æ¦‚å¿µçš„å®é™…è¿ç”¨
- æƒ…å¢ƒåŒ–çš„å­¦ä¹ 

ç”Ÿæˆ2é“åº”ç”¨é¢˜ï¼š
1. æ¡ˆä¾‹åˆ†æé¢˜
2. å®é™…é—®é¢˜è§£å†³é¢˜

è¿”å›JSONæ ¼å¼ï¼š
{{
    "questions": [
        {{
            "level": "application",
            "type": "case_study",
            "stem": "é¢˜å¹²",
            "correct_answer": "æ­£ç¡®ç­”æ¡ˆ",
            "explanation": "ç­”æ¡ˆè§£é‡Š",
            "cognitive_focus": "æµ‹è¯•çš„è®¤çŸ¥è¦ç‚¹"
        }}
    ]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

# ========== ç¬¬å››å±‚ï¼šè®¤çŸ¥è´Ÿè·ä¼˜åŒ–å±‚ ==========

@tool
def simplify_question_language(question_json: str, target_level: str = "undergraduate") -> str:
    """
    ç®€åŒ–é¢˜ç›®è¯­è¨€ï¼Œé™ä½è®¤çŸ¥è´Ÿè·
    
    Args:
        question_json (str): åŸå§‹é¢˜ç›®JSON
        target_level (str): ç›®æ ‡æ°´å¹³
        
    Returns:
        str: ä¼˜åŒ–åçš„é¢˜ç›®JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.3)
    
    prompt = f"""
ä¼˜åŒ–é¢˜ç›®è¯­è¨€ï¼Œé™ä½è®¤çŸ¥è´Ÿè·ï¼š

åŸå§‹é¢˜ç›®ï¼š{question_json}
ç›®æ ‡æ°´å¹³ï¼š{target_level}

ä¼˜åŒ–è¦æ±‚ï¼š
1. ä½¿ç”¨ç®€å•ç›´ç™½çš„è¯­è¨€
2. é¿å…å¤æ‚çš„å¥å¼ç»“æ„
3. ç¡®ä¿æ¯é¢˜åªè€ƒå¯Ÿä¸€ä¸ªçŸ¥è¯†ç‚¹
4. æä¾›å¿…è¦çš„èƒŒæ™¯ä¿¡æ¯
5. å»é™¤å¤šä½™çš„ä¿®é¥°è¯

è¿”å›ä¼˜åŒ–åçš„é¢˜ç›®JSONï¼Œä¿æŒç›¸åŒçš„ç»“æ„ã€‚
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def ensure_single_concept_focus(question_json: str) -> str:
    """
    ç¡®ä¿é¢˜ç›®èšç„¦å•ä¸€çŸ¥è¯†ç‚¹
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.3)
    
    prompt = f"""
æ£€æŸ¥å¹¶ä¼˜åŒ–é¢˜ç›®ï¼Œç¡®ä¿å•ä¸€çŸ¥è¯†ç‚¹èšç„¦ï¼š

é¢˜ç›®ï¼š{question_json}

æ£€æŸ¥è¦æ±‚ï¼š
1. é¢˜ç›®æ˜¯å¦åªæµ‹è¯•ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µ
2. æ˜¯å¦æœ‰å¤šä½™çš„å¹²æ‰°ä¿¡æ¯
3. é€‰é¡¹æ˜¯å¦æ¸…æ™°åŒºåˆ†
4. è®¤çŸ¥è¦æ±‚æ˜¯å¦ä¸€è‡´

è¿”å›ä¼˜åŒ–åçš„é¢˜ç›®JSONï¼Œå¦‚æœæ²¡æœ‰é—®é¢˜åˆ™ä¿æŒåŸæ ·ã€‚
"""
        
    response = model.invoke(prompt)
    return response.content

# ========== ç¬¬äº”å±‚ï¼šæ™ºèƒ½åé¦ˆå±‚ ==========

@tool
def diagnose_error_types(question_json: str, common_mistakes: List[str]) -> str:
    """
    é¢„æµ‹å­¦ä¹ è€…å¯èƒ½çš„é”™è¯¯ç±»å‹
    
    Args:
        question_json (str): é¢˜ç›®JSON
        common_mistakes (List[str]): å¸¸è§é”™è¯¯ç±»å‹
        
    Returns:
        str: é”™è¯¯è¯Šæ–­JSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.5)
    
    prompt = f"""
åˆ†æå­¦ä¹ è€…åœ¨æ­¤é¢˜ç›®ä¸Šå¯èƒ½çŠ¯çš„é”™è¯¯ï¼š

é¢˜ç›®ï¼š{question_json}
å¸¸è§é”™è¯¯ç±»å‹ï¼š{common_mistakes}

åˆ†æè¦æ±‚ï¼š
1. é¢„æµ‹3-5ç§å¯èƒ½çš„é”™è¯¯ç±»å‹
2. åˆ†æé”™è¯¯çš„è®¤çŸ¥æ ¹æº
3. ä¸ºæ¯ç§é”™è¯¯è®¾è®¡é’ˆå¯¹æ€§åé¦ˆ

è¿”å›JSONæ ¼å¼ï¼š
{{
    "error_predictions": [
        {{
            "error_type": "é”™è¯¯ç±»å‹",
            "description": "é”™è¯¯æè¿°", 
            "cognitive_cause": "è®¤çŸ¥åŸå› ",
            "frequency": "high/medium/low",
            "remediation_strategy": "è¡¥æ•‘ç­–ç•¥"
        }}
    ]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool
def generate_personalized_feedback(student_answer: str, correct_answer: str, error_diagnosis: str) -> str:
    """
    ç”Ÿæˆä¸ªæ€§åŒ–çš„å­¦ä¹ æŒ‡å¯¼åé¦ˆ
    
    Args:
        student_answer (str): å­¦ç”Ÿç­”æ¡ˆ
        correct_answer (str): æ­£ç¡®ç­”æ¡ˆ
        error_diagnosis (str): é”™è¯¯è¯Šæ–­
        
    Returns:
        str: ä¸ªæ€§åŒ–åé¦ˆJSON
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.6)
    
    prompt = f"""
ç”Ÿæˆä¸ªæ€§åŒ–çš„å­¦ä¹ æŒ‡å¯¼åé¦ˆï¼š

å­¦ç”Ÿç­”æ¡ˆï¼š{student_answer}
æ­£ç¡®ç­”æ¡ˆï¼š{correct_answer}  
é”™è¯¯è¯Šæ–­ï¼š{error_diagnosis}

åé¦ˆè¦æ±‚ï¼š
1. å…ˆè‚¯å®šç­”å¯¹çš„éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
2. æŒ‡å‡ºå…·ä½“çš„é”™è¯¯ç‚¹
3. è§£é‡Šä¸ºä»€ä¹ˆä¼šæœ‰è¿™ä¸ªé”™è¯¯
4. æä¾›å­¦ä¹ å»ºè®®å’Œèµ„æº
5. é¼“åŠ±ç»§ç»­å­¦ä¹ 

è¿”å›JSONæ ¼å¼ï¼š
{{
    "positive_reinforcement": "è‚¯å®šçš„éƒ¨åˆ†",
    "error_identification": "é”™è¯¯è¯†åˆ«",
    "explanation": "é”™è¯¯åŸå› è§£é‡Š",
    "correct_reasoning": "æ­£ç¡®æ€è·¯å¼•å¯¼", 
    "learning_suggestions": ["å­¦ä¹ å»ºè®®1", "å­¦ä¹ å»ºè®®2"],
    "next_steps": "ä¸‹ä¸€æ­¥å­¦ä¹ æ–¹å‘",
    "encouragement": "é¼“åŠ±è¯è¯­"
}}
"""
    
    response = model.invoke(prompt)
    return response.content

@tool 
def recommend_learning_path(current_level: str, mastered_concepts: List[str], target_concepts: List[str]) -> str:
    """
    æ¨èä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„
    """
    model = ChatTongyi(model="qwen-max-latest", temperature=0.5)
    
    prompt = f"""
ä¸ºå­¦ä¹ è€…æ¨èä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„ï¼š

å½“å‰æ°´å¹³ï¼š{current_level}
å·²æŒæ¡æ¦‚å¿µï¼š{mastered_concepts}
ç›®æ ‡æ¦‚å¿µï¼š{target_concepts}

æ¨èè¦æ±‚ï¼š
1. åˆ†æçŸ¥è¯†å·®è·
2. åˆ¶å®šå¾ªåºæ¸è¿›çš„å­¦ä¹ è®¡åˆ’
3. æ¨èå­¦ä¹ èµ„æºå’Œæ–¹æ³•
4. è®¾ç½®å­¦ä¹ é‡Œç¨‹ç¢‘

è¿”å›JSONæ ¼å¼ï¼š
{{
    "knowledge_gap": "çŸ¥è¯†å·®è·åˆ†æ",
    "learning_plan": [
        {{
            "step": 1,
            "concept": "å­¦ä¹ æ¦‚å¿µ",
            "duration": "å»ºè®®æ—¶é—´",
            "resources": ["èµ„æº1", "èµ„æº2"]
        }}
    ],
    "milestones": ["é‡Œç¨‹ç¢‘1", "é‡Œç¨‹ç¢‘2"],
    "study_tips": ["å­¦ä¹ å»ºè®®1", "å­¦ä¹ å»ºè®®2"]
}}
"""
    
    response = model.invoke(prompt)
    return response.content

# ========== åŸºç¡€å·¥å…·ï¼ˆå…¼å®¹æ€§ï¼‰ ==========

@tool
def save_question_to_database(level_id: str, question_json: str) -> str:
    """
    å°†ç”Ÿæˆçš„é¢˜ç›®ä¿å­˜åˆ°æ•°æ®åº“
    """
    try:
        if DatabaseManager is None:
            return "âš ï¸ æ•°æ®åº“ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œé¢˜ç›®æœªä¿å­˜"
        
        question_data = json.loads(question_json)
        db_manager = DatabaseManager()
        
        # å¤„ç†æ–°æ ¼å¼çš„é¢˜ç›®æ•°æ®
        if "questions" in question_data:
            # æ–°æ ¼å¼ï¼šåŒ…å«å¤šä¸ªé¢˜ç›®
            results = []
            for q in question_data["questions"]:
                question_id = db_manager.insert_question(
                    level_id=level_id,
                    stem=q["stem"],
                    content_json=q,
                    answer_json={"correct_answer": q.get("correct_answer"), "explanation": q.get("explanation")},
                    score=1,
                    created_by="enhanced_agent"
                )
                results.append(f"é¢˜ç›®ID: {question_id}")
            return f"âœ… ä¿å­˜æˆåŠŸï¼{', '.join(results)}"
        else:
            # æ—§æ ¼å¼å…¼å®¹
            question_id = db_manager.insert_question(
                level_id=level_id,
                stem=question_data.get("stem", "é¢˜ç›®"),
                content_json=question_data,
                answer_json=question_data.get("answer_json", {}),
                score=1,
                created_by="enhanced_agent"
            )
            return f"âœ… é¢˜ç›®ä¿å­˜æˆåŠŸï¼é¢˜ç›®ID: {question_id}"
        
    except Exception as e:
        logger.error(f"ä¿å­˜é¢˜ç›®å¤±è´¥: {e}")
        return f"âŒ ä¿å­˜é¢˜ç›®å¤±è´¥: {str(e)}"

@tool
def get_question_generation_stats() -> str:
    """
    è·å–é¢˜ç›®ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    """
    try:
        if DatabaseManager is None:
            return "âš ï¸ æ•°æ®åº“ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œæ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯"
        
        db_manager = DatabaseManager()
        with db_manager.get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_questions,
                    COUNT(DISTINCT level_id) as levels_with_questions
                FROM questions 
                WHERE created_by = 'enhanced_agent'
            """)
            stats = cursor.fetchone()
        
        return f"""
ğŸ“Š å¢å¼ºAgenté¢˜ç›®ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯

æ€»ä½“ç»Ÿè®¡:
- å¢å¼ºAgentç”Ÿæˆé¢˜ç›®æ€»æ•°: {stats['total_questions']} é¢˜
- æ¶‰åŠå…³å¡æ•°: {stats['levels_with_questions']} ä¸ª

ç”Ÿæˆå¼•æ“: enhanced_agentï¼ˆåŸºäºè®¤çŸ¥ç§‘å­¦ï¼‰
"""
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"

# ========== Agentåˆ›å»ºå‡½æ•° ==========

def create_enhanced_question_generation_agent():
    """åˆ›å»ºå¢å¼ºçš„é¢˜ç›®ç”ŸæˆAgent"""

    # åˆå§‹åŒ–LLM
    model = ChatTongyi(
        model="qwen-max-latest",
        top_p=0.8,
        streaming=True,
        temperature=0.7,
        max_retries=3
    )
    
    # å®šä¹‰åˆ†å±‚å·¥å…·åˆ—è¡¨
    tools = [
        # çŸ¥è¯†ç»“æ„åˆ†æå±‚
        extract_core_concepts,
        analyze_knowledge_dependencies, 
        classify_cognitive_levels,
        
        # æ¦‚å¿µé”šå®šå±‚
        map_existing_knowledge,
        generate_concept_analogies,
        
        # åˆ†å±‚é¢˜ç›®ç”Ÿæˆå±‚
        generate_memory_level_questions,
        generate_understanding_level_questions,
        generate_application_level_questions,
        
        # è®¤çŸ¥è´Ÿè·ä¼˜åŒ–å±‚
        simplify_question_language,
        ensure_single_concept_focus,
        
        # æ™ºèƒ½åé¦ˆå±‚
        diagnose_error_types,
        generate_personalized_feedback,
        recommend_learning_path,
        
        # åŸºç¡€å·¥å…·
        save_question_to_database,
        get_question_generation_stats
    ]
    
    # ç³»ç»Ÿæç¤º
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŸºäºè®¤çŸ¥ç§‘å­¦çš„æ™ºèƒ½é¢˜ç›®ç”ŸæˆåŠ©æ‰‹ã€‚

ä½ çš„æ ¸å¿ƒç†å¿µï¼š
1. åˆ†å±‚å­¦ä¹ ç†è®ºï¼šä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼Œå±‚å±‚é€’è¿›
2. è®¤çŸ¥è´Ÿè·ç†è®ºï¼šç®€åŒ–è¯­è¨€ï¼Œèšç„¦å•ä¸€çŸ¥è¯†ç‚¹ï¼Œæä¾›æ¸…æ™°åé¦ˆ
3. æ¦‚å¿µé”šå®šç†è®ºï¼šå°†æ–°çŸ¥è¯†ä¸å·²æœ‰çŸ¥è¯†å»ºç«‹è¿æ¥

å·¥ä½œæµç¨‹ï¼š
1. é¦–å…ˆåˆ†æè®ºæ–‡çš„çŸ¥è¯†ç»“æ„å’Œæ¦‚å¿µä¾èµ–å…³ç³»
2. ä¸ºå¤æ‚æ¦‚å¿µå»ºç«‹ä¸å¸¸è¯†çš„è¿æ¥
3. æŒ‰è®¤çŸ¥å±‚æ¬¡ç”Ÿæˆä¸åŒéš¾åº¦çš„é¢˜ç›®
4. ä¼˜åŒ–è¯­è¨€è¡¨è¾¾ï¼Œé™ä½è®¤çŸ¥è´Ÿè·
5. è®¾è®¡æ™ºèƒ½åé¦ˆæœºåˆ¶ï¼Œå¸®åŠ©å­¦ä¹ è€…ç†è§£é”™è¯¯

å§‹ç»ˆè®°ä½ï¼šå¥½çš„é¢˜ç›®ä¸ä»…æµ‹è¯•çŸ¥è¯†ï¼Œæ›´è¦ä¿ƒè¿›ç†è§£å’Œå­¦ä¹ ã€‚"""
    
    # åˆ›å»ºAgent
    agent = create_react_agent(
        model=model,
        tools=tools,
        prompt=system_prompt
    )
    
    return agent
    
def run_enhanced_question_generation_agent(message: str, thread_id: str = "1") -> dict:
    """
    è¿è¡Œå¢å¼ºçš„é¢˜ç›®ç”ŸæˆAgent
    
    Args:
        message (str): ç”¨æˆ·æ¶ˆæ¯
        thread_id (str): ä¼šè¯ID
        
    Returns:
        dict: å¤„ç†ç»“æœ
    """
    try:
        agent = create_enhanced_question_generation_agent()
        
        # æ‰§è¡ŒAgent
        config = {"configurable": {"thread_id": thread_id}}
        
        responses = []
        for chunk in agent.stream({"messages": [("human", message)]}, config=config):
            if "agent" in chunk:
                if chunk["agent"].get("messages"):
                    for msg in chunk["agent"]["messages"]:
                        if hasattr(msg, 'content'):
                            responses.append(msg.content)
            elif "tools" in chunk:
                for tool_name, tool_result in chunk["tools"].items():
                    responses.append(f"ğŸ”§ {tool_name}: {tool_result}")
        
        return {"status": "success", "responses": responses, "message": "å¢å¼ºé¢˜ç›®ç”Ÿæˆå®Œæˆ"}
        
    except Exception as e:
        logger.error(f"è¿è¡Œå¢å¼ºAgentå¤±è´¥: {e}")
        return {"status": "error", "message": str(e), "responses": []}

# ========== ä¾¿æ·å‡½æ•° ==========

def generate_enhanced_questions_for_paper(paper_content: str, paper_title: str) -> dict:
    """
    ä¸ºæŒ‡å®šè®ºæ–‡ç”Ÿæˆå¢å¼ºé¢˜ç›®çš„ä¾¿æ·æ–¹æ³•
    """
    message = f"""
è¯·ä½¿ç”¨å¢å¼ºçš„é¢˜ç›®ç”Ÿæˆæµç¨‹ä¸ºä»¥ä¸‹è®ºæ–‡ç”Ÿæˆé¢˜ç›®ï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{paper_title}
è®ºæ–‡å†…å®¹ï¼š{paper_content[:1000]}...

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š
1. æå–æ ¸å¿ƒæ¦‚å¿µ
2. åˆ†æçŸ¥è¯†ä¾èµ–å…³ç³»
3. ä¸ºæ¯ä¸ªæ¦‚å¿µç”Ÿæˆä¸åŒè®¤çŸ¥å±‚æ¬¡çš„é¢˜ç›®
4. ä¼˜åŒ–é¢˜ç›®è¯­è¨€å’Œç»“æ„
"""
    return run_enhanced_question_generation_agent(message, thread_id=f"paper_{hash(paper_title)}")

if __name__ == "__main__":
    print("ğŸ¤– å¢å¼ºé¢˜ç›®ç”ŸæˆAgent å¯åŠ¨")
    print("=" * 60)

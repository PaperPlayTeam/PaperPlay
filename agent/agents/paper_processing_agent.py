# Import relevant functionality
from langchain_community.chat_models import ChatTongyi
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from langchain.tools import tool
import sys
import os
import json

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… å·²åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡")
except ImportError:
    print("âš ï¸  æœªå®‰è£…python-dotenvåŒ…ï¼Œæ— æ³•åŠ è½½.envæ–‡ä»¶")
    print("   å¯ä»¥é€šè¿‡ 'pip install python-dotenv' å®‰è£…")

# æ·»åŠ utilsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from utils import (
    PDFTextExtractor,
    DatabaseManager,
    VectorStoreManager,
    search_similar_papers_tool,
    search_similar_concepts_tool,
    hybrid_search_tool,
    get_vector_store_stats_tool,
    add_paper_to_vector_store_tool
)

# åˆ›å»ºPDFæ–‡æœ¬æå–å·¥å…·åŒ…è£…å™¨
@tool
def pdf_text_extraction_tool(file_path: str) -> str:
    """
    ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å’Œå…ƒæ•°æ®
    
    Args:
        file_path (str): PDFæ–‡ä»¶çš„è·¯å¾„
        
    Returns:
        str: åŒ…å«æå–ç»“æœçš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ã€å…¨æ–‡ç­‰ä¿¡æ¯
    """
    try:
        extractor = PDFTextExtractor()
        result = extractor.extract_text_from_pdf(file_path)
        
        if result["status"] == "success":
            paper = result["paper"]
            return f"""
PDFæ–‡æœ¬æå–æˆåŠŸï¼

è®ºæ–‡ä¿¡æ¯ï¼š
- æ ‡é¢˜: {paper['title']}
- ä½œè€…: {', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper['authors']}
- æ‘˜è¦: {paper['abstract'][:300]}...
- ArXiv ID: {paper['arxiv_id']}
- å¹´ä»½: {paper['year']}
- å…¨æ–‡é•¿åº¦: {paper['parsed_text_length']} å­—ç¬¦

æå–çš„å…¨æ–‡å†…å®¹å·²åŒ…å«åœ¨ç»“æœä¸­ã€‚
"""
        else:
            return f"PDFæ–‡æœ¬æå–å¤±è´¥: {result['message']}"
            
    except Exception as e:
        return f"å¤„ç†PDFæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def complete_paper_processing_tool(file_path: str) -> str:
    """
    å®Œæ•´çš„è®ºæ–‡å¤„ç†æµç¨‹ï¼šæå–æ–‡æœ¬ -> å­˜å‚¨åˆ°æ•°æ®åº“ -> æ·»åŠ åˆ°å‘é‡åº“
    
    Args:
        file_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: å¤„ç†ç»“æœæè¿°
    """
    try:
        # 1. æå–PDFæ–‡æœ¬å’Œå…ƒæ•°æ®
        pdf_extractor = PDFTextExtractor()
        result = pdf_extractor.extract_text_from_pdf(file_path)
        
        if result["status"] != "success":
            return f"âŒ PDFæå–å¤±è´¥: {result['message']}"
        
        paper_data = result["paper"]
        
        # 2. å­˜å‚¨åˆ°ä¼ ç»Ÿæ•°æ®åº“ (é€‚é…æ–°API)
        db_manager = DatabaseManager()
        
        # é€‚é…æ–°çš„å­—æ®µæ ¼å¼
        paper_author = "; ".join(paper_data["authors"]) if isinstance(paper_data["authors"], list) else str(paper_data["authors"])
        paper_pub_ym = str(paper_data.get("year", "æœªçŸ¥"))  # ä»å¹´ä»½è½¬æ¢ä¸ºå‘è¡¨å¹´æœˆ
        
        paper_id = db_manager.insert_paper(
            title=paper_data["title"],
            paper_author=paper_author,
            paper_pub_ym=paper_pub_ym,
            paper_citation_count="0"  # MVPç‰ˆæœ¬é»˜è®¤ä¸º0
        )
        
        # 3. æ·»åŠ åˆ°å‘é‡åº“
        vector_manager = VectorStoreManager()
        
        # ä½¿ç”¨æ‘˜è¦å’Œæ ‡é¢˜ä½œä¸ºå‘é‡å­˜å‚¨çš„æ–‡æœ¬  
        vector_text = f"{paper_data['title']}\n\n{paper_data['abstract']}"
        if len(vector_text) < 100:  # å¦‚æœæ‘˜è¦å¤ªçŸ­ï¼Œä½¿ç”¨éƒ¨åˆ†æ­£æ–‡
            vector_text += f"\n\n{paper_data['parsed_text'][:1000]}"
        
        vector_id = vector_manager.add_paper_embedding(
            paper_id=paper_id,
            simplified_text=vector_text,
            metadata={
                "title": paper_data["title"],
                "authors": paper_author,
                "year": paper_data.get("year", "æœªçŸ¥"),
                "arxiv_id": paper_data.get("arxiv_id", ""),
                "file_path": file_path
            }
        )
        
        return f"""âœ… è®ºæ–‡å¤„ç†å®Œæˆï¼
ğŸ“„ æ ‡é¢˜: {paper_data['title']}
ğŸ‘¥ ä½œè€…: {paper_author}
ğŸ“… å¹´ä»½: {paper_data.get('year', 'æœªçŸ¥')}
ğŸ†” æ•°æ®åº“ID: {paper_id}
ğŸ” å‘é‡ID: {vector_id}
ğŸ“Š æ•°æ®æ¥æº: {result.get('metadata_source', 'æœªçŸ¥')}"""
        
    except Exception as e:
        return f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def get_database_stats_tool() -> str:
    """
    è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        str: æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        db_manager = DatabaseManager()
        stats = db_manager.get_system_stats()
        
        formatted_stats = {
            "æ€»å­¦ç§‘æ•°": stats.get('total_subjects', 0),
            "æ€»è®ºæ–‡æ•°": stats.get('total_papers', 0),
            "æ€»å…³å¡æ•°": stats.get('total_levels', 0), 
            "æ€»é¢˜ç›®æ•°": stats.get('total_questions', 0),
            "å¹³å‡æ¯å…³å¡é¢˜ç›®æ•°": stats.get('avg_questions_per_level', 0),
            "å¹³å‡é¢˜ç›®åˆ†å€¼": stats.get('avg_question_score', 0),
            "æ•°æ®åº“çŠ¶æ€": "æ­£å¸¸è¿è¡Œ"
        }
        
        # æ ¼å¼åŒ–è¾“å‡º
        result = "ğŸ“Š **æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯**\n\n"
        for key, value in formatted_stats.items():
            result += f"â€¢ {key}: {value}\n"
        
        return result
        
    except Exception as e:
        return f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"

# Create the agent with ChatTongyi (é€šä¹‰åƒé—®)
memory = MemorySaver()

# æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è®¾ç½®
api_key = os.getenv("DASHSCOPE_API_KEY")
if not api_key:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ°DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    print("   è¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ : DASHSCOPE_API_KEY=your-api-key")
    sys.exit(1)

# åˆå§‹åŒ–é€šä¹‰åƒé—®æ¨¡å‹
model = ChatTongyi(
    model="qwen-max-latest",
    top_p=0.8,
    streaming=True,
    temperature=0.7,
    max_retries=3
)

# åˆ›å»ºå®Œæ•´çš„å·¥å…·åˆ—è¡¨
tools = [
    pdf_text_extraction_tool,           # PDFæ–‡æœ¬æå–
    complete_paper_processing_tool,     # å®Œæ•´è®ºæ–‡å¤„ç†æµç¨‹
    search_similar_papers_tool,         # æœç´¢ç›¸ä¼¼è®ºæ–‡
    search_similar_concepts_tool,       # æœç´¢ç›¸ä¼¼æ¦‚å¿µ
    hybrid_search_tool,                 # æ··åˆæœç´¢
    get_vector_store_stats_tool,        # å‘é‡åº“ç»Ÿè®¡
    get_database_stats_tool,            # æ•°æ®åº“ç»Ÿè®¡
    add_paper_to_vector_store_tool      # æ‰‹åŠ¨æ·»åŠ è®ºæ–‡åˆ°å‘é‡åº“
]

agent_executor = create_react_agent(model, tools, checkpointer=memory)

def run_paper_processing_agent(message: str, thread_id: str = "1") -> dict:
    """
    è¿è¡Œä»£ç†å¹¶å¤„ç†ç”¨æˆ·æ¶ˆæ¯
    
    Args:
        message (str): ç”¨æˆ·æ¶ˆæ¯
        thread_id (str): çº¿ç¨‹IDï¼Œç”¨äºç»´æŠ¤ä¼šè¯çŠ¶æ€
        
    Returns:
        dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
    """
    config = {"configurable": {"thread_id": thread_id}}
    
    responses = []
    
    try:
        for chunk in agent_executor.stream(
            {"messages": [("user", message)]}, config
        ):
            if "agent" in chunk:
                response = chunk["agent"]["messages"][0].content
                print(response)
                responses.append(response)
            elif "tools" in chunk:
                # å¯é€‰ï¼šæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {chunk}")
        
        return {
            "status": "success",
            "responses": responses,
            "message": "å¤„ç†å®Œæˆ"
        }
        
    except Exception as e:
        error_msg = f"âŒ è¿è¡Œå‡ºé”™: {e}"
        print(error_msg)
        return {
            "status": "error",
            "message": str(e)
        }

def process_single_paper(file_path: str) -> dict:
    """
    å¤„ç†å•ä¸ªè®ºæ–‡æ–‡ä»¶çš„ä¾¿æ·æ–¹æ³•
    
    Args:
        file_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: å¤„ç†ç»“æœ
    """
    message = f"è¯·ä½¿ç”¨å®Œæ•´è®ºæ–‡å¤„ç†æµç¨‹å¤„ç†è¿™ä¸ªPDFæ–‡ä»¶: {file_path}"
    return run_paper_processing_agent(message, thread_id=f"paper_{hash(file_path)}")

if __name__ == "__main__":
    print("ğŸ¤– å¢å¼ºç‰ˆè®ºæ–‡å¤„ç†ä»£ç†å·²å¯åŠ¨ï¼")
    print("æ”¯æŒçš„åŠŸèƒ½:")
    print("  ğŸ“„ PDFæ–‡æœ¬æå–")
    print("  ğŸ’¾ æ•°æ®åº“å­˜å‚¨")
    print("  ğŸ” å‘é‡æœç´¢")
    print("  ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("ä½ å¯ä»¥è®©æˆ‘å¸®ä½ å®Œæ•´å¤„ç†PDFæ–‡ä»¶ã€‚")
    print("ç¤ºä¾‹: 'è¯·å®Œæ•´å¤„ç† /path/to/paper.pdf'")
    print("=" * 50)
    
    # ç¤ºä¾‹ç”¨æ³•
    user_message = "è¯·å®Œæ•´å¤„ç† /home/bugsmith/paperplay/papers/1706.03762v7.pdf"
    print(f"ç¤ºä¾‹æ¶ˆæ¯: {user_message}")
    
    try:
        result = run_paper_processing_agent(user_message)
        print(f"\nå¤„ç†ç»“æœ: {result['status']}")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥DASHSCOPE_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
#!/usr/bin/env python3
"""
ä»concepts.jsonæ–‡ä»¶ç”Ÿæˆç±»æ¯”å¼•å…¥å¼é—®é¢˜å¹¶å­˜å‚¨åˆ°æ•°æ®åº“
ä¸ºæ¯ä¸ªæ¦‚å¿µç”Ÿæˆå¼•å…¥é¢˜+æ¦‚å¿µé¢˜çš„é…å¯¹é—®é¢˜
"""

import os
import sys
import json
import sqlite3
import logging
import uuid
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from langchain_community.chat_models import ChatTongyi
from langchain_core.prompts import ChatPromptTemplate

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… å·²åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡")
except ImportError:
    print("âš ï¸  æœªå®‰è£…python-dotenvåŒ…ï¼Œæ— æ³•åŠ è½½.envæ–‡ä»¶")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AnalogicalQuestionGenerator:
    """ç±»æ¯”å¼•å…¥å¼é—®é¢˜ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        
        # åˆå§‹åŒ–LLMæ¨¡å‹
        self.model = ChatTongyi(
            model="qwen-max-latest",
            top_p=0.8,
            temperature=0.7,  
            max_retries=3
        )
        
        # æ•°æ®åº“è·¯å¾„
        self.db_path = os.path.join(project_root, 'sqlite', 'paperplay.db')
        
        # åˆ›å»ºé—®é¢˜ç”Ÿæˆçš„promptæ¨¡æ¿
        self.question_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„æ•™è‚²ä¸“å®¶ï¼Œä¸“é—¨è®¾è®¡ç±»æ¯”å¼•å…¥å¼é¢˜ç›®æ¥å¸®åŠ©å­¦ä¹ è€…ç†è§£å¤æ‚çš„è®¡ç®—æœºæ¦‚å¿µã€‚

ä½ çš„ä»»åŠ¡æ˜¯åŸºäºç»™å®šçš„æ¦‚å¿µä¿¡æ¯ï¼Œç”Ÿæˆä¸€é“å®Œæ•´çš„ç±»æ¯”å¼•å…¥å¼é¢˜ç›®ï¼ŒåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š

1. **å¼•å…¥é¢˜ï¼ˆç”Ÿæ´»ç±»æ¯”ï¼‰**ï¼šç”¨ç”Ÿæ´»ä¸­å¸¸è§çš„åœºæ™¯ç±»æ¯”è®¡ç®—æœºæ¦‚å¿µï¼Œæå‡ºé—®é¢˜å¹¶ç»™å‡º4ä¸ªé€‰é¡¹
2. **æ¦‚å¿µé¢˜ï¼ˆæŠ€æœ¯è§£é‡Šï¼‰**ï¼šè§£é‡Šè®¡ç®—æœºæ¦‚å¿µåï¼Œæå‡ºç›´æ¥ç›¸å…³çš„é—®é¢˜å¹¶ç»™å‡º4ä¸ªé€‰é¡¹

**é‡è¦è¦æ±‚**ï¼š
- å¼•å…¥é¢˜åº”æ„å»º**æ™®é€‚æ€§çš„æ—¥å¸¸æƒ…å¢ƒ**ï¼Œé¿å…ä½¿ç”¨å¦‚â€œæŸæŸäººâ€ç­‰å…·ä½“ä»£è¯æˆ–åå­—ï¼Œä»¥ç¡®ä¿æ‰€æœ‰å­¦ä¹ è€…éƒ½èƒ½äº§ç”Ÿå…±é¸£ã€‚
- å¼•å…¥é¢˜å’Œæ¦‚å¿µé¢˜çš„æ­£ç¡®ç­”æ¡ˆå¿…é¡»åœ¨åŒä¸€ä¸ªé€‰é¡¹ä½ç½®ï¼ˆå¦‚éƒ½æ˜¯Bï¼‰
- ä¸¤ä¸ªé—®é¢˜çš„é€»è¾‘å¿…é¡»é«˜åº¦å¯¹åº”
- ç±»æ¯”è¦è´´åˆ‡ã€è‡ªç„¶ã€æ˜“æ‡‚
- é€‰é¡¹è¦æœ‰åˆç†çš„å¹²æ‰°æ€§
- è¯­è¨€è¦ç”ŸåŠ¨ã€å‡†ç¡®

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
  "lead_in_question": "ç”Ÿæ´»åŒ–çš„å¼•å…¥é—®é¢˜æè¿°",
  "lead_in_options": [
    "A. é€‰é¡¹Aå†…å®¹",
    "B. é€‰é¡¹Bå†…å®¹", 
    "C. é€‰é¡¹Cå†…å®¹",
    "D. é€‰é¡¹Då†…å®¹"
  ],
  "concept_explanation": "æ¦‚å¿µè§£é‡Šæ®µè½ï¼Œè¿æ¥ç±»æ¯”å’ŒæŠ€æœ¯æ¦‚å¿µ",
  "lead_in_question": "è®¡ç®—æœºæ¦‚å¿µç›¸å…³çš„é—®é¢˜",
  "concept_options": [
    "A. é€‰é¡¹Aå†…å®¹",
    "B. é€‰é¡¹Bå†…å®¹",
    "C. é€‰é¡¹Cå†…å®¹", 
    "D. é€‰é¡¹Då†…å®¹"
  ],
  "correct_option": "B",
  "explanation": "ä¸ºä»€ä¹ˆè¿™ä¸ªé€‰é¡¹æ˜¯æ­£ç¡®çš„ï¼Œè§£é‡Šç±»æ¯”å’Œæ¦‚å¿µçš„å¯¹åº”å…³ç³»"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼"""),
            ("human", """è®ºæ–‡æ ‡é¢˜ï¼š{paper_title}
æ¦‚å¿µåç§°ï¼š{concept_name}
æ¦‚å¿µè§£é‡Šï¼š{concept_explanation}
é‡è¦æ€§è¯„åˆ†ï¼š{importance_score}

è¯·åŸºäºè¿™ä¸ªæ¦‚å¿µç”Ÿæˆä¸€é“ç±»æ¯”å¼•å…¥å¼é¢˜ç›®ï¼š""")
        ])
        
        logger.info("ç±»æ¯”é—®é¢˜ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def generate_question_for_concept(self, paper_title: str, concept: Dict, max_retries: int = 3) -> Optional[Dict]:
        """ä¸ºå•ä¸ªæ¦‚å¿µç”Ÿæˆç±»æ¯”å¼•å…¥å¼é—®é¢˜"""
        concept_name = concept.get('name', '')
        concept_explanation = concept.get('explanation', '')
        importance_score = concept.get('importance_score', 0)
        
        logger.info(f"å¼€å§‹ä¸ºæ¦‚å¿µç”Ÿæˆé—®é¢˜: {concept_name}")
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(max_retries):
            try:
                logger.info(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ç”Ÿæˆé—®é¢˜")
                
                # æ„å»ºprompt
                prompt = self.question_prompt.format_messages(
                    paper_title=paper_title,
                    concept_name=concept_name,
                    concept_explanation=concept_explanation,
                    importance_score=importance_score
                )
                
                # è°ƒç”¨LLM
                response = self.model.invoke(prompt)
                response_text = response.content.strip()
                
                # è§£æJSONå“åº”
                question_data = self._parse_question_response(response_text)
                
                if question_data and self._validate_question_structure(question_data):
                    logger.info(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•æˆåŠŸç”Ÿæˆé—®é¢˜")
                    return question_data
                else:
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•ç”Ÿæˆçš„é—®é¢˜æ ¼å¼ä¸æ­£ç¡®")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç¨ä½œç­‰å¾…
                if attempt < max_retries - 1:
                    import time
                    wait_time = (attempt + 1) * 2
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    
            except Exception as e:
                logger.error(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    logger.info(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                else:
                    logger.error(f"æ‰€æœ‰ {max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›fallbacké—®é¢˜
        logger.warning(f"ä¸ºæ¦‚å¿µ {concept_name} ç”Ÿæˆé—®é¢˜å¤±è´¥ï¼Œä½¿ç”¨fallback")
        return self._create_fallback_question(concept_name, concept_explanation)

    def _parse_question_response(self, response_text: str) -> Optional[Dict]:
        """è§£æLLMå“åº”ä¸­çš„é—®é¢˜JSON"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            cleaned_text = response_text.strip()
            
            # å°è¯•ç›´æ¥è§£æJSON
            if cleaned_text.startswith('{'):
                try:
                    data = json.loads(cleaned_text)
                    return data
                except json.JSONDecodeError:
                    pass
            
            # å°è¯•æå–markdownä»£ç å—ä¸­çš„JSON
            import re
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',
                r'```\s*(\{.*?\})\s*```',
                r'`(\{.*?\})`',
            ]
            
            for pattern in json_patterns:
                json_match = re.search(pattern, cleaned_text, re.DOTALL)
                if json_match:
                    try:
                        json_str = json_match.group(1).strip()
                        data = json.loads(json_str)
                        return data
                    except json.JSONDecodeError:
                        continue
            
            logger.error(f"æ— æ³•è§£æLLMå“åº”ä¸ºJSON: {cleaned_text[:200]}...")
            return None
            
        except Exception as e:
            logger.error(f"è§£æé—®é¢˜å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _validate_question_structure(self, question_data: Dict) -> bool:
        """éªŒè¯é—®é¢˜æ•°æ®ç»“æ„çš„å®Œæ•´æ€§"""
        required_fields = [
            'lead_in_question', 'lead_in_options', 
            'concept_explanation', 'concept_question', 'concept_options',
            'correct_option', 'explanation'
        ]
        
        for field in required_fields:
            if field not in question_data:
                logger.warning(f"é—®é¢˜æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # éªŒè¯é€‰é¡¹æ•°é‡
        if len(question_data.get('lead_in_options', [])) != 4:
            logger.warning("å¼•å…¥é¢˜é€‰é¡¹æ•°é‡ä¸æ˜¯4ä¸ª")
            return False
            
        if len(question_data.get('concept_options', [])) != 4:
            logger.warning("æ¦‚å¿µé¢˜é€‰é¡¹æ•°é‡ä¸æ˜¯4ä¸ª")
            return False
        
        # éªŒè¯æ­£ç¡®é€‰é¡¹æ ¼å¼
        correct_option = question_data.get('correct_option', '')
        if correct_option not in ['A', 'B', 'C', 'D']:
            logger.warning(f"æ­£ç¡®é€‰é¡¹æ ¼å¼ä¸æ­£ç¡®: {correct_option}")
            return False
        
        return True

    def _create_fallback_question(self, concept_name: str, concept_explanation: str) -> Dict:
        """åˆ›å»ºfallbacké—®é¢˜ï¼ˆå½“LLMç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        return {
            "lead_in_question": f"æƒ³è±¡ä½ éœ€è¦å‘æœ‹å‹è§£é‡Šä¸€ä¸ªå¤æ‚çš„æ¦‚å¿µï¼š'{concept_name}'ï¼Œä½ ä¼šé‡‡ç”¨ä»€ä¹ˆæ–¹æ³•ï¼Ÿ",
            "lead_in_options": [
                "A. ç›´æ¥èƒŒè¯µä¸“ä¸šå®šä¹‰ï¼Œè®©æœ‹å‹è‡ªå·±ç†è§£",
                "B. ç”¨ç”Ÿæ´»ä¸­çš„ä¾‹å­æ¥ç±»æ¯”ï¼Œè®©å¤æ‚æ¦‚å¿µå˜å¾—å®¹æ˜“ç†è§£",
                "C. è¦æ±‚æœ‹å‹å…ˆå­¦ä¼šæ‰€æœ‰ç›¸å…³çš„åŸºç¡€çŸ¥è¯†",
                "D. ç”»ä¸€ä¸ªå¤æ‚çš„æŠ€æœ¯å›¾è¡¨æ¥è¯´æ˜"
            ],
            "concept_explanation": f"åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œ{concept_name}æ˜¯ä¸€ä¸ªé‡è¦æ¦‚å¿µã€‚{concept_explanation[:100]}...",
            "concept_question": f"å…³äº{concept_name}çš„æ ¸å¿ƒä½œç”¨ï¼Œä»¥ä¸‹å“ªé¡¹æè¿°æœ€å‡†ç¡®ï¼Ÿ",
            "concept_options": [
                "A. ä¸»è¦ç”¨äºæé«˜ç³»ç»Ÿçš„è¿è¡Œé€Ÿåº¦",
                "B. é€šè¿‡ç‰¹å®šçš„æœºåˆ¶å’Œæ–¹æ³•ï¼Œå¸®åŠ©ç³»ç»Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†å¤æ‚ä¿¡æ¯",
                "C. ä»…ç”¨äºæ•°æ®å­˜å‚¨å’Œç®¡ç†",
                "D. ä¸“é—¨å¤„ç†ç”¨æˆ·ç•Œé¢çš„æ˜¾ç¤ºé—®é¢˜"
            ],
            "correct_option": "B",
            "explanation": f"å°±åƒç”¨ç”Ÿæ´»ä¾‹å­æ¥è§£é‡Šå¤æ‚æ¦‚å¿µä¸€æ ·ï¼Œ{concept_name}é€šè¿‡å…¶ç‰¹å®šçš„æœºåˆ¶å¸®åŠ©è®¡ç®—æœºç³»ç»Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†ä¿¡æ¯ã€‚"
        }

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        logger.info(f"æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–: {db_path}")

    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return sqlite3.connect(self.db_path)

    def ensure_subject_exists(self) -> str:
        """ç¡®ä¿æœºå™¨å­¦ä¹ å­¦ç§‘å­˜åœ¨ï¼Œè¿”å›subject_id"""
        subject_id = "ml_ai_subject"
        subject_name = "æœºå™¨å­¦ä¹ ä¸äººå·¥æ™ºèƒ½"
        current_time = int(datetime.now().timestamp())
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            cursor.execute("SELECT id FROM subjects WHERE id = ?", (subject_id,))
            if cursor.fetchone():
                logger.info(f"å­¦ç§‘å·²å­˜åœ¨: {subject_name}")
                return subject_id
            
            # åˆ›å»ºå­¦ç§‘
            cursor.execute("""
                INSERT INTO subjects (id, name, description, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?)
            """, (subject_id, subject_name, "æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç­‰AIç›¸å…³è®ºæ–‡", current_time, current_time))
            
            conn.commit()
            logger.info(f"åˆ›å»ºæ–°å­¦ç§‘: {subject_name}")
            return subject_id

    def insert_paper_and_level(self, subject_id: str, paper_info: Dict) -> Tuple[str, str]:
        """æ’å…¥è®ºæ–‡å’Œå¯¹åº”çš„å…³å¡ï¼Œè¿”å›(paper_id, level_id)"""
        paper_id = f"paper_{paper_info['arxiv_id']}"
        level_id = f"level_{paper_info['arxiv_id']}"
        current_time = int(datetime.now().timestamp())
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ£€æŸ¥è®ºæ–‡æ˜¯å¦å·²å­˜åœ¨
            cursor.execute("SELECT id FROM papers WHERE id = ?", (paper_id,))
            if cursor.fetchone():
                logger.info(f"è®ºæ–‡å·²å­˜åœ¨: {paper_info['title'][:50]}...")
                # è¿”å›ç°æœ‰çš„paper_idå’Œlevel_id
                cursor.execute("SELECT id FROM levels WHERE paper_id = ?", (paper_id,))
                existing_level = cursor.fetchone()
                if existing_level:
                    return paper_id, existing_level[0]
            
            # æ’å…¥è®ºæ–‡
            authors_str = ', '.join(paper_info.get('authors', []))[:500]  # é™åˆ¶é•¿åº¦
            cursor.execute("""
                INSERT OR REPLACE INTO papers 
                (id, subject_id, title, paper_author, paper_pub_ym, paper_citation_count, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                paper_id, subject_id, paper_info['title'][:500], 
                authors_str, str(paper_info.get('year', 2023)), 
                str(paper_info.get('citation_count', 0)), current_time, current_time
            ))
            
            # æ’å…¥å…³å¡
            cursor.execute("""
                INSERT OR REPLACE INTO levels 
                (id, paper_id, name, pass_condition, meta_json, x, y, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                level_id, paper_id, f"{paper_info['title'][:50]}...æ¦‚å¿µç†è§£å…³å¡", 
                "å®Œæˆæ‰€æœ‰æ¦‚å¿µé—®é¢˜", json.dumps({"concepts_count": 5}), 
                0, 0, current_time, current_time
            ))
            
            conn.commit()
            logger.info(f"æ’å…¥è®ºæ–‡å’Œå…³å¡: {paper_info['title'][:50]}...")
            return paper_id, level_id

    def insert_question(self, level_id: str, question_data: Dict, concept_name: str) -> Tuple[str, str]:
        """æ’å…¥ä¸¤ä¸ªé—®é¢˜åˆ°æ•°æ®åº“ï¼šå¼•å…¥é¢˜å’Œæ¦‚å¿µé¢˜"""
        current_time = int(datetime.now().timestamp())
        
        # ç”Ÿæˆä¸¤ä¸ªé—®é¢˜çš„ID
        lead_in_question_id = str(uuid.uuid4())
        concept_question_id = str(uuid.uuid4())
        
        # æ„å»ºå¼•å…¥é¢˜å†…å®¹JSON
        lead_in_content_json = {
            "type": "analogical_lead_in",
            "concept_name": concept_name,
            "question": question_data['lead_in_question'],
            "options": question_data['lead_in_options']
        }
        
        # æ„å»ºæ¦‚å¿µé¢˜å†…å®¹JSON
        concept_content_json = {
            "type": "conceptual_question",
            "concept_name": concept_name,
            "concept_explanation": question_data['concept_explanation'],
            "question": question_data['concept_question'],
            "options": question_data['concept_options']
        }
        
        # æ„å»ºç­”æ¡ˆJSONï¼ˆä¸¤ä¸ªé¢˜çš„æ­£ç¡®ç­”æ¡ˆåº”è¯¥æ˜¯ä¸€è‡´çš„ï¼‰
        answer_json = {
            "correct_option": question_data['correct_option'],
            "explanation": question_data['explanation']
        }
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ’å…¥å¼•å…¥é¢˜
            cursor.execute("""
                INSERT INTO questions 
                (id, level_id, stem, content_json, answer_json, score, created_by, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                lead_in_question_id, level_id, f"{concept_name} - å¼•å…¥é¢˜", 
                json.dumps(lead_in_content_json, ensure_ascii=False),
                json.dumps(answer_json, ensure_ascii=False),
                5,  # å¼•å…¥é¢˜åˆ†æ•°
                "system_generated", current_time
            ))
            
            # æ’å…¥æ¦‚å¿µé¢˜
            cursor.execute("""
                INSERT INTO questions 
                (id, level_id, stem, content_json, answer_json, score, created_by, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                concept_question_id, level_id, f"{concept_name} - æ¦‚å¿µé¢˜", 
                json.dumps(concept_content_json, ensure_ascii=False),
                json.dumps(answer_json, ensure_ascii=False),
                5,  # æ¦‚å¿µé¢˜åˆ†æ•°
                "system_generated", current_time
            ))
            
            conn.commit()
            logger.info(f"æ’å…¥ä¸¤ä¸ªé—®é¢˜: {concept_name} (å¼•å…¥é¢˜ + æ¦‚å¿µé¢˜)")
            return lead_in_question_id, concept_question_id

def load_concept_json(file_path: str) -> Optional[Dict]:
    """åŠ è½½æ¦‚å¿µJSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except Exception as e:
        logger.error(f"åŠ è½½æ¦‚å¿µæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None

def process_all_concept_files():
    """å¤„ç†æ‰€æœ‰æ¦‚å¿µæ–‡ä»¶"""
    papers_dir = Path(project_root) / "papers"
    
    if not papers_dir.exists():
        print("âŒ papersç›®å½•ä¸å­˜åœ¨")
        return
    
    # è·å–æ‰€æœ‰æ¦‚å¿µJSONæ–‡ä»¶
    concept_files = list(papers_dir.glob("*.concepts.json"))
    
    if not concept_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•.concepts.jsonæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(concept_files)} ä¸ªæ¦‚å¿µæ–‡ä»¶")
    print(f"ğŸ’¡ é¢„æœŸç”Ÿæˆ: {len(concept_files) * 5 * 2} é“é—®é¢˜ï¼ˆ{len(concept_files)} æ–‡ä»¶ Ã— 5 æ¦‚å¿µ Ã— 2 é—®é¢˜ï¼‰")
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        question_generator = AnalogicalQuestionGenerator()
        db_manager = DatabaseManager(os.path.join(project_root, 'sqlite', 'paperplay.db'))
        print("âœ… ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ç¡®ä¿å­¦ç§‘å­˜åœ¨
    subject_id = db_manager.ensure_subject_exists()
    
    # å¤„ç†ç»“æœç»Ÿè®¡
    results = {
        "total_files": len(concept_files),
        "success_files": 0,
        "failed_files": 0,
        "total_questions": 0,
        "success_questions": 0,
        "failed_questions": 0,
        "details": []
    }
    
    for i, concept_file in enumerate(concept_files, 1):
        arxiv_id = concept_file.stem.replace('.concepts', '')
        print(f"\nğŸ” [{i}/{len(concept_files)}] å¤„ç†: {arxiv_id}")
        print("-" * 50)
        
        try:
            # åŠ è½½æ¦‚å¿µæ•°æ®
            concept_data = load_concept_json(str(concept_file))
            if not concept_data:
                results["failed_files"] += 1
                results["details"].append({
                    "file": str(concept_file),
                    "status": "failed",
                    "message": "æ¦‚å¿µæ–‡ä»¶åŠ è½½å¤±è´¥"
                })
                print(f"âŒ æ¦‚å¿µæ–‡ä»¶åŠ è½½å¤±è´¥: {arxiv_id}")
                continue
            
            paper_info = concept_data['paper_info']
            concepts = concept_data['concepts']
            
            print(f"ğŸ“„ è®ºæ–‡: {paper_info['title'][:50]}...")
            print(f"ğŸ§  æ¦‚å¿µæ•°é‡: {len(concepts)}")
            
            # æ’å…¥è®ºæ–‡å’Œå…³å¡
            paper_id, level_id = db_manager.insert_paper_and_level(subject_id, paper_info)
            
            # ä¸ºæ¯ä¸ªæ¦‚å¿µç”Ÿæˆé—®é¢˜
            file_success_count = 0
            file_failed_count = 0
            
            for j, concept in enumerate(concepts, 1):
                concept_name = concept.get('name', f'æ¦‚å¿µ{j}')
                print(f"\n  ğŸ¯ [{j}/5] ç”Ÿæˆé—®é¢˜: {concept_name}")
                
                try:
                    # ç”Ÿæˆé—®é¢˜
                    question_data = question_generator.generate_question_for_concept(
                        paper_info['title'], concept
                    )
                    
                    if question_data:
                        # å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆç°åœ¨è¿”å›ä¸¤ä¸ªé—®é¢˜IDï¼‰
                        lead_in_id, concept_id = db_manager.insert_question(level_id, question_data, concept_name)
                        file_success_count += 2  # å› ä¸ºç”Ÿæˆäº†ä¸¤ä¸ªé—®é¢˜
                        results["success_questions"] += 2  # å› ä¸ºç”Ÿæˆäº†ä¸¤ä¸ªé—®é¢˜
                        print(f"  âœ… é—®é¢˜ç”ŸæˆæˆåŠŸ: {concept_name}")
                        print(f"     å¼•å…¥é¢˜ID: {lead_in_id[:8]}... | {question_data['lead_in_question'][:30]}...")
                        print(f"     æ¦‚å¿µé¢˜ID: {concept_id[:8]}... | {question_data['concept_question'][:30]}...")
                        print(f"     æ­£ç¡®ç­”æ¡ˆ: {question_data['correct_option']}")
                    else:
                        file_failed_count += 1
                        results["failed_questions"] += 1
                        print(f"  âŒ é—®é¢˜ç”Ÿæˆå¤±è´¥: {concept_name}")
                        
                    results["total_questions"] += 1
                    
                except Exception as e:
                    file_failed_count += 1
                    results["failed_questions"] += 1
                    results["total_questions"] += 1
                    print(f"  âŒ å¤„ç†æ¦‚å¿µå¼‚å¸¸: {concept_name} - {e}")
            
            # æ–‡ä»¶å¤„ç†ç»“æœ
            if file_failed_count == 0:
                results["success_files"] += 1
                results["details"].append({
                    "file": str(concept_file),
                    "status": "success",
                    "message": f"æˆåŠŸç”Ÿæˆ {file_success_count} é“é—®é¢˜",
                    "questions_count": file_success_count
                })
                print(f"\nâœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {arxiv_id} ({file_success_count}é“é—®é¢˜)")
            else:
                results["failed_files"] += 1
                results["details"].append({
                    "file": str(concept_file),
                    "status": "partial",
                    "message": f"éƒ¨åˆ†æˆåŠŸ: {file_success_count}æˆåŠŸ, {file_failed_count}å¤±è´¥",
                    "questions_count": file_success_count
                })
                print(f"\nâš ï¸ æ–‡ä»¶éƒ¨åˆ†å®Œæˆ: {arxiv_id} ({file_success_count}æˆåŠŸ, {file_failed_count}å¤±è´¥)")
                
        except Exception as e:
            results["failed_files"] += 1
            results["details"].append({
                "file": str(concept_file),
                "status": "failed",
                "message": str(e)
            })
            print(f"\nâŒ æ–‡ä»¶å¤„ç†å¼‚å¸¸: {arxiv_id} - {e}")
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ¯ é—®é¢˜ç”Ÿæˆç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"ğŸ“ æ–‡ä»¶å¤„ç†: {results['success_files']}æˆåŠŸ / {results['failed_files']}å¤±è´¥ / {results['total_files']}æ€»è®¡")
    print(f"â“ é—®é¢˜ç”Ÿæˆ: {results['success_questions']}æˆåŠŸ / {results['failed_questions']}å¤±è´¥ / {results['total_questions']}æ€»è®¡")
    print(f"ğŸ“Š æˆåŠŸç‡: {results['success_questions']/results['total_questions']*100:.1f}%" if results['total_questions'] > 0 else "ğŸ“Š æˆåŠŸç‡: 0%")
    print(f"ğŸ’¡ æ³¨æ„: æ¯ä¸ªæ¦‚å¿µç”Ÿæˆ2é“é—®é¢˜ï¼ˆå¼•å…¥é¢˜+æ¦‚å¿µé¢˜ï¼‰")
    
    if results['success_questions'] > 0:
        print(f"\nâœ… æˆåŠŸç”Ÿæˆçš„é—®é¢˜:")
        for detail in results['details']:
            if detail['status'] in ['success', 'partial'] and detail.get('questions_count', 0) > 0:
                arxiv_id = Path(detail['file']).stem.replace('.concepts', '')
                concepts_count = detail['questions_count'] // 2  # æ¯ä¸ªæ¦‚å¿µ2é“é¢˜
                print(f"  - {arxiv_id}: {detail['questions_count']} é“é—®é¢˜ï¼ˆ{concepts_count} ä¸ªæ¦‚å¿µ Ã— 2ï¼‰")
    
    print(f"\nğŸ’¾ æ‰€æœ‰é—®é¢˜å·²å­˜å‚¨åˆ°æ•°æ®åº“: {db_manager.db_path}")
    print("ğŸ‰ å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    print("ğŸš€ ç±»æ¯”å¼•å…¥å¼é—®é¢˜ç”Ÿæˆç³»ç»Ÿ")
    print("ä»æ¦‚å¿µJSONæ–‡ä»¶ç”Ÿæˆæ•™è‚²é—®é¢˜å¹¶å­˜å‚¨åˆ°æ•°æ®åº“")
    print("=" * 60)
    
    process_all_concept_files()

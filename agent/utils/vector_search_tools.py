from langchain.tools import tool
from .vector_store_manager import VectorStoreManager
import json
import logging
from typing import Dict, Any

# åˆ›å»ºå…¨å±€çš„å‘é‡ç®¡ç†å™¨å®ä¾‹
_vector_manager = None

def get_vector_manager() -> VectorStoreManager:
    """è·å–å‘é‡ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _vector_manager
    if _vector_manager is None:
        _vector_manager = VectorStoreManager()
    return _vector_manager

@tool
def search_similar_papers_tool(query_text: str, max_results: int = 5) -> str:
    """
    æœç´¢ä¸æŸ¥è¯¢æ–‡æœ¬ç›¸ä¼¼çš„è®ºæ–‡
    
    Args:
        query_text (str): æŸ¥è¯¢æ–‡æœ¬ï¼Œå¯ä»¥æ˜¯é—®é¢˜ã€å…³é”®è¯æˆ–æè¿°
        max_results (int): è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª
        
    Returns:
        str: åŒ…å«ç›¸ä¼¼è®ºæ–‡ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€ä½œè€…ã€ç›¸ä¼¼åº¦ç­‰
    """
    try:
        vector_manager = get_vector_manager()
        
        # é™åˆ¶æœ€å¤§ç»“æœæ•°é‡
        n_results = min(max_results, 10)
        
        results = vector_manager.search_similar_papers(query_text, n_results)
        
        if not results:
            return "æœªæ‰¾åˆ°ç›¸ä¼¼çš„è®ºæ–‡ã€‚å¯èƒ½å‘é‡åº“ä¸­è¿˜æ²¡æœ‰è®ºæ–‡æ•°æ®ï¼Œæˆ–è€…æŸ¥è¯¢æ–‡æœ¬æ²¡æœ‰åŒ¹é…çš„å†…å®¹ã€‚"
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            formatted_result = {
                "æ’å": i,
                "ç›¸ä¼¼åº¦": f"{result.get('similarity', 0):.3f}",
                "è®ºæ–‡æ ‡é¢˜": metadata.get('title', 'æœªçŸ¥'),
                "ä½œè€…": metadata.get('authors', 'æœªçŸ¥'),
                "å¹´ä»½": metadata.get('year', 'æœªçŸ¥'),
                "arXiv ID": metadata.get('arxiv_id', 'æœªçŸ¥'),
                "æ–‡æ¡£æ‘˜è¦": result.get('document', '')[:200] + "..." if len(result.get('document', '')) > 200 else result.get('document', ''),
                "å‘é‡ID": result.get('vector_id', '')
            }
            formatted_results.append(formatted_result)
        
        return f"""
æ‰¾åˆ°äº† {len(results)} ç¯‡ç›¸ä¼¼è®ºæ–‡ï¼š

{json.dumps(formatted_results, ensure_ascii=False, indent=2)}

æœç´¢å®Œæˆï¼ä»¥ä¸Šè®ºæ–‡æŒ‰ç›¸ä¼¼åº¦ä»é«˜åˆ°ä½æ’åºã€‚
"""
        
    except Exception as e:
        return f"æœç´¢ç›¸ä¼¼è®ºæ–‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def search_similar_concepts_tool(query_text: str, max_results: int = 5) -> str:
    """
    æœç´¢ä¸æŸ¥è¯¢æ–‡æœ¬ç›¸ä¼¼çš„æ¦‚å¿µ
    
    Args:
        query_text (str): æŸ¥è¯¢æ–‡æœ¬ï¼Œå¯ä»¥æ˜¯æ¦‚å¿µåç§°ã€æè¿°æˆ–é—®é¢˜
        max_results (int): è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª
        
    Returns:
        str: åŒ…å«ç›¸ä¼¼æ¦‚å¿µä¿¡æ¯çš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬æ¦‚å¿µåç§°ã€æè¿°ã€ç›¸ä¼¼åº¦ç­‰
    """
    try:
        vector_manager = get_vector_manager()
        
        # é™åˆ¶æœ€å¤§ç»“æœæ•°é‡
        n_results = min(max_results, 10)
        
        results = vector_manager.search_similar_concepts(query_text, n_results)
        
        if not results:
            return "æœªæ‰¾åˆ°ç›¸ä¼¼çš„æ¦‚å¿µã€‚å¯èƒ½å‘é‡åº“ä¸­è¿˜æ²¡æœ‰æ¦‚å¿µæ•°æ®ï¼Œæˆ–è€…æŸ¥è¯¢æ–‡æœ¬æ²¡æœ‰åŒ¹é…çš„å†…å®¹ã€‚"
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            formatted_result = {
                "æ’å": i,
                "ç›¸ä¼¼åº¦": f"{result.get('similarity', 0):.3f}",
                "æ¦‚å¿µåç§°": metadata.get('concept_name', 'æœªçŸ¥'),
                "ç±»åˆ«": metadata.get('category', 'æœªçŸ¥'),
                "éš¾åº¦çº§åˆ«": metadata.get('difficulty_level', 'æœªçŸ¥'),
                "æ¦‚å¿µæè¿°": result.get('document', '')[:300] + "..." if len(result.get('document', '')) > 300 else result.get('document', ''),
                "å‘é‡ID": result.get('vector_id', '')
            }
            formatted_results.append(formatted_result)
        
        return f"""
æ‰¾åˆ°äº† {len(results)} ä¸ªç›¸ä¼¼æ¦‚å¿µï¼š

{json.dumps(formatted_results, ensure_ascii=False, indent=2)}

æœç´¢å®Œæˆï¼ä»¥ä¸Šæ¦‚å¿µæŒ‰ç›¸ä¼¼åº¦ä»é«˜åˆ°ä½æ’åºã€‚
"""
        
    except Exception as e:
        return f"æœç´¢ç›¸ä¼¼æ¦‚å¿µæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def hybrid_search_tool(query_text: str, search_papers: bool = True, search_concepts: bool = True, max_results: int = 5) -> str:
    """
    æ··åˆæœç´¢è®ºæ–‡å’Œæ¦‚å¿µ
    
    Args:
        query_text (str): æŸ¥è¯¢æ–‡æœ¬
        search_papers (bool): æ˜¯å¦æœç´¢è®ºæ–‡ï¼Œé»˜è®¤True
        search_concepts (bool): æ˜¯å¦æœç´¢æ¦‚å¿µï¼Œé»˜è®¤True
        max_results (int): æ¯ç§ç±»å‹çš„æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª
        
    Returns:
        str: åŒ…å«è®ºæ–‡å’Œæ¦‚å¿µæœç´¢ç»“æœçš„ç»¼åˆä¿¡æ¯
    """
    try:
        vector_manager = get_vector_manager()
        
        # é™åˆ¶æœ€å¤§ç»“æœæ•°é‡
        n_results = min(max_results, 8)
        
        results = vector_manager.hybrid_search(
            query_text, 
            search_papers=search_papers, 
            search_concepts=search_concepts, 
            n_results=n_results
        )
        
        response_parts = []
        
        if search_papers and results.get("papers"):
            paper_results = []
            for i, result in enumerate(results["papers"], 1):
                metadata = result.get('metadata', {})
                paper_result = {
                    "æ’å": i,
                    "ç›¸ä¼¼åº¦": f"{result.get('similarity', 0):.3f}",
                    "æ ‡é¢˜": metadata.get('title', 'æœªçŸ¥'),
                    "ä½œè€…": metadata.get('authors', 'æœªçŸ¥'),
                    "å¹´ä»½": metadata.get('year', 'æœªçŸ¥')
                }
                paper_results.append(paper_result)
            
            response_parts.append(f"""
ğŸ“„ ç›¸å…³è®ºæ–‡ ({len(paper_results)} ç¯‡):
{json.dumps(paper_results, ensure_ascii=False, indent=2)}
""")
        
        if search_concepts and results.get("concepts"):
            concept_results = []
            for i, result in enumerate(results["concepts"], 1):
                metadata = result.get('metadata', {})
                concept_result = {
                    "æ’å": i,
                    "ç›¸ä¼¼åº¦": f"{result.get('similarity', 0):.3f}",
                    "æ¦‚å¿µ": metadata.get('concept_name', 'æœªçŸ¥'),
                    "ç±»åˆ«": metadata.get('category', 'æœªçŸ¥'),
                    "éš¾åº¦": metadata.get('difficulty_level', 'æœªçŸ¥')
                }
                concept_results.append(concept_result)
            
            response_parts.append(f"""
ğŸ§  ç›¸å…³æ¦‚å¿µ ({len(concept_results)} ä¸ª):
{json.dumps(concept_results, ensure_ascii=False, indent=2)}
""")
        
        if not response_parts:
            return "æœªæ‰¾åˆ°ç›¸å…³çš„è®ºæ–‡æˆ–æ¦‚å¿µã€‚"
        
        return "ğŸ” æ··åˆæœç´¢ç»“æœï¼š\n" + "\n".join(response_parts)
        
    except Exception as e:
        return f"æ··åˆæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def get_vector_store_stats_tool() -> str:
    """
    è·å–å‘é‡åº“çš„ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        str: å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬è®ºæ–‡æ•°é‡ã€æ¦‚å¿µæ•°é‡ã€åµŒå…¥æ¨¡å‹ç­‰
    """
    try:
        vector_manager = get_vector_manager()
        stats = vector_manager.get_collection_stats()
        
        if not stats:
            return "æ— æ³•è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯ã€‚"
        
        formatted_stats = {
            "è®ºæ–‡å‘é‡æ•°é‡": stats.get('papers_count', 0),
            "æ¦‚å¿µå‘é‡æ•°é‡": stats.get('concepts_count', 0),
            "æ€»å‘é‡æ•°é‡": stats.get('total_vectors', 0),
            "åµŒå…¥æ¨¡å‹": stats.get('embedding_model', 'æœªçŸ¥'),
            "çŠ¶æ€": "æ­£å¸¸è¿è¡Œ" if stats.get('total_vectors', 0) > 0 else "å‘é‡åº“ä¸ºç©º"
        }
        
        return f"""
ğŸ“Š å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯ï¼š

{json.dumps(formatted_stats, ensure_ascii=False, indent=2)}

å‘é‡åº“è¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚
"""
        
    except Exception as e:
        return f"è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

@tool
def add_paper_to_vector_store_tool(paper_text: str, paper_id: int, title: str = "", authors: str = "", arxiv_id: str = "") -> str:
    """
    å°†è®ºæ–‡æ–‡æœ¬æ·»åŠ åˆ°å‘é‡åº“ä¸­
    
    Args:
        paper_text (str): è®ºæ–‡çš„æ–‡æœ¬å†…å®¹ï¼ˆé€šå¸¸æ˜¯ç®€åŒ–åçš„æ–‡æœ¬ï¼‰
        paper_id (int): è®ºæ–‡åœ¨æ•°æ®åº“ä¸­çš„ID
        title (str): è®ºæ–‡æ ‡é¢˜ï¼Œå¯é€‰
        authors (str): è®ºæ–‡ä½œè€…ï¼Œå¯é€‰  
        arxiv_id (str): arXiv IDï¼Œå¯é€‰
        
    Returns:
        str: æ·»åŠ ç»“æœä¿¡æ¯
    """
    try:
        vector_manager = get_vector_manager()
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "title": title or "æœªçŸ¥æ ‡é¢˜",
            "authors": authors or "æœªçŸ¥ä½œè€…",
            "arxiv_id": arxiv_id or "æœªçŸ¥"
        }
        
        # æ·»åŠ å‘é‡
        vector_id = vector_manager.add_paper_embedding(
            paper_id=paper_id,
            simplified_text=paper_text,
            metadata=metadata
        )
        
        return f"""
âœ… æˆåŠŸå°†è®ºæ–‡æ·»åŠ åˆ°å‘é‡åº“ï¼

- å‘é‡ID: {vector_id}
- è®ºæ–‡ID: {paper_id}
- æ ‡é¢˜: {title or 'æœªæä¾›'}
- æ–‡æœ¬é•¿åº¦: {len(paper_text)} å­—ç¬¦

ç°åœ¨å¯ä»¥é€šè¿‡ç›¸ä¼¼æ€§æœç´¢æ‰¾åˆ°è¿™ç¯‡è®ºæ–‡äº†ã€‚
"""
        
    except Exception as e:
        return f"æ·»åŠ è®ºæ–‡åˆ°å‘é‡åº“å¤±è´¥: {str(e)}" 
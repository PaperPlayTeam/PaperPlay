#!/usr/bin/env python3
"""
Paperplayä¸»ç¨‹åº - æ‰¹é‡å¤„ç†è®ºæ–‡æ–‡ä»¶
å®Œæ•´çš„è®ºæ–‡å¤„ç†æµç¨‹ï¼šPDFè§£æ -> æ•°æ®åº“å­˜å‚¨ -> å‘é‡å­˜å‚¨
"""

from agents.paper_processing_agent import run_paper_processing_agent, process_single_paper
from agents.concept_extraction_agent import ConceptExtractionAgent
from utils import download_paper_list, PDFTextExtractor
import os
import json
from pathlib import Path

def get_paper_files(papers_dir: str = "papers") -> list:
    """è·å–è®ºæ–‡ç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    paper_files = []
    
    if not os.path.exists(papers_dir):
        print(f"âŒ è®ºæ–‡ç›®å½•ä¸å­˜åœ¨: {papers_dir}")
        return paper_files
    
    for file in os.listdir(papers_dir):
        if file.endswith(".pdf"):
            paper_path = os.path.join(papers_dir, file)
            paper_files.append(paper_path)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(paper_files)} ä¸ªPDFæ–‡ä»¶")
    return paper_files

def download_predefined_papers() -> dict:
    """ä¸‹è½½é¢„å®šä¹‰çš„è®ºæ–‡åˆ—è¡¨"""
    paper_list_for_aiagent = [
        "https://arxiv.org/abs/1706.03762",  # Attention Is All You Need
        "https://arxiv.org/abs/1810.04805",  # BERT
        "https://arxiv.org/abs/2005.14165",  # GPT-3
        "https://arxiv.org/abs/2201.11903",  # Chain-of-Thought Prompting
        "https://arxiv.org/abs/2210.03629",  # ReAct
        "https://arxiv.org/abs/2302.04761",  # Toolformer
        "https://arxiv.org/abs/2304.03442",  # Generative Agents: Interactive Simulacra of Human Behavior
        "https://arxiv.org/abs/2310.08560",  # MEMGPT
        "https://arxiv.org/abs/2304.11477",  # LLM+P
        "https://arxiv.org/abs/2303.03378"   # PaLM-E: An Embodied Multimodal Language Model
    ]
    
    print("ğŸ“¥ å¼€å§‹ä¸‹è½½é¢„å®šä¹‰è®ºæ–‡åˆ—è¡¨...")
    result = download_paper_list(paper_list_for_aiagent)
    return result

def process_papers_batch(paper_files: list) -> dict:
    """æ‰¹é‡å¤„ç†è®ºæ–‡æ–‡ä»¶"""
    results = {
        "total": len(paper_files),
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "details": []
    }
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(paper_files)} ç¯‡è®ºæ–‡...")
    print("=" * 60)
    
    for i, paper_path in enumerate(paper_files, 1):
        print(f"\nğŸ“„ [{i}/{len(paper_files)}] å¤„ç†è®ºæ–‡: {os.path.basename(paper_path)}")
        print("-" * 40)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è§£æç»“æœ
        md_path = paper_path + ".md"
        if os.path.exists(md_path):
            results["skipped"] += 1
            results["details"].append({
                "file": paper_path,
                "status": "skipped",
                "message": "å·²æœ‰è§£æç»“æœï¼Œè·³è¿‡å¤„ç†"
            })
            print(f"â­ï¸ å·²æœ‰è§£æç»“æœï¼Œè·³è¿‡: {os.path.basename(paper_path)}")
            continue
        
        try:
            # ä½¿ç”¨å¢å¼ºç‰ˆagentå¤„ç†å•ä¸ªè®ºæ–‡
            result = process_single_paper(paper_path)
            
            if result["status"] == "success":
                results["success"] += 1
                results["details"].append({
                    "file": paper_path,
                    "status": "success",
                    "message": "å¤„ç†å®Œæˆ"
                })
                print(f"âœ… è®ºæ–‡å¤„ç†æˆåŠŸ: {os.path.basename(paper_path)}")
            else:
                results["failed"] += 1
                results["details"].append({
                    "file": paper_path,
                    "status": "failed",
                    "message": result.get("message", "æœªçŸ¥é”™è¯¯")
                })
                print(f"âŒ è®ºæ–‡å¤„ç†å¤±è´¥: {os.path.basename(paper_path)}")
                print(f"   é”™è¯¯ä¿¡æ¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            results["failed"] += 1
            results["details"].append({
                "file": paper_path,
                "status": "failed", 
                "message": str(e)
            })
            print(f"âŒ è®ºæ–‡å¤„ç†å¼‚å¸¸: {os.path.basename(paper_path)}")
            print(f"   å¼‚å¸¸ä¿¡æ¯: {str(e)}")
    
    return results

def process_concepts_batch(paper_files: list) -> dict:
    """æ‰¹é‡å¤„ç†è®ºæ–‡æ¦‚å¿µæå–"""
    results = {
        "total": len(paper_files),
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "details": []
    }
    
    print(f"\nğŸ§  å¼€å§‹æ‰¹é‡æ¦‚å¿µæå– {len(paper_files)} ç¯‡è®ºæ–‡...")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¦‚å¿µæå–agentå’ŒPDFæå–å™¨
    concept_agent = ConceptExtractionAgent()
    pdf_extractor = PDFTextExtractor()
    
    for i, paper_path in enumerate(paper_files, 1):
        print(f"\nğŸ” [{i}/{len(paper_files)}] æ¦‚å¿µæå–: {os.path.basename(paper_path)}")
        print("-" * 40)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è§£æç»“æœ
        md_path = paper_path + ".md"
        if not os.path.exists(md_path):
            results["failed"] += 1
            results["details"].append({
                "file": paper_path,
                "status": "failed",
                "message": "ç¼ºå°‘è§£æç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆè¿›è¡Œè®ºæ–‡å¤„ç†"
            })
            print(f"âŒ ç¼ºå°‘è§£æç»“æœæ–‡ä»¶: {os.path.basename(paper_path)}")
            continue
        
        try:
            # 1. æå–arXiv IDç”¨äºæ£€æŸ¥æ¦‚å¿µæ•°æ®åº“
            arxiv_id = pdf_extractor.extract_arxiv_id(paper_path)
            
            # 2. æ£€æŸ¥æ¦‚å¿µæ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¯¥è®ºæ–‡
            if arxiv_id:
                existing_paper = concept_agent.get_paper_concepts(arxiv_id)
                if existing_paper and len(existing_paper.get('concepts', [])) > 0:
                    results["skipped"] += 1
                    results["details"].append({
                        "file": paper_path,
                        "status": "skipped",
                        "message": f"æ¦‚å¿µå·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç† (å·²æœ‰{len(existing_paper['concepts'])}ä¸ªæ¦‚å¿µ)",
                        "arxiv_id": arxiv_id,
                        "concepts_count": len(existing_paper['concepts'])
                    })
                    print(f"â­ï¸ æ¦‚å¿µå·²å­˜åœ¨ï¼Œè·³è¿‡: {os.path.basename(paper_path)}")
                    print(f"   ArXiv ID: {arxiv_id}")
                    print(f"   å·²æœ‰æ¦‚å¿µæ•°: {len(existing_paper['concepts'])}")
                    continue
            
            # 3. é¦–å…ˆæå–PDFå†…å®¹
            extraction_result = pdf_extractor.extract_text_from_pdf(paper_path)
            
            if extraction_result["status"] != "success":
                results["failed"] += 1
                results["details"].append({
                    "file": paper_path,
                    "status": "failed",
                    "message": f"PDFæå–å¤±è´¥: {extraction_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                })
                print(f"âŒ PDFæå–å¤±è´¥: {os.path.basename(paper_path)}")
                continue
            
            # 4. è¿›è¡Œæ¦‚å¿µæå–
            paper_data = extraction_result["paper"]
            concept_result = concept_agent.process_paper_concepts(paper_data)
            
            if concept_result["status"] == "success":
                results["success"] += 1
                results["details"].append({
                    "file": paper_path,
                    "status": "success",
                    "message": concept_result["message"],
                    "concepts_count": len(concept_result["concepts"]),
                    "arxiv_id": concept_result["arxiv_id"]
                })
                print(f"âœ… æ¦‚å¿µæå–æˆåŠŸ: {os.path.basename(paper_path)}")
                print(f"   æå–æ¦‚å¿µæ•°: {len(concept_result['concepts'])}")
                print(f"   ArXiv ID: {concept_result['arxiv_id']}")
            else:
                results["failed"] += 1
                results["details"].append({
                    "file": paper_path,
                    "status": "failed",
                    "message": concept_result.get("message", "æ¦‚å¿µæå–å¤±è´¥")
                })
                print(f"âŒ æ¦‚å¿µæå–å¤±è´¥: {os.path.basename(paper_path)}")
                print(f"   é”™è¯¯ä¿¡æ¯: {concept_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            results["failed"] += 1
            results["details"].append({
                "file": paper_path,
                "status": "failed",
                "message": str(e)
            })
            print(f"âŒ æ¦‚å¿µæå–å¼‚å¸¸: {os.path.basename(paper_path)}")
            print(f"   å¼‚å¸¸ä¿¡æ¯: {str(e)}")
    
    return results

def show_final_stats():
    """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯...")
    
    # è·å–æ•°æ®åº“ç»Ÿè®¡
    db_result = run_paper_processing_agent("è¯·è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯", thread_id="stats_db")
    
    # è·å–å‘é‡åº“ç»Ÿè®¡  
    vector_result = run_paper_processing_agent("è¯·è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯", thread_id="stats_vector")
    
    # è·å–æ¦‚å¿µæ•°æ®åº“ç»Ÿè®¡
    try:
        concept_agent = ConceptExtractionAgent()
        concept_stats = concept_agent.get_database_stats()
        
        print("\nğŸ§  æ¦‚å¿µæ•°æ®åº“ç»Ÿè®¡:")
        print(f"  â€¢ æ€»è®ºæ–‡æ•°: {concept_stats.get('total_papers', 0)}")
        print(f"  â€¢ æ€»æ¦‚å¿µæ•°: {concept_stats.get('total_concepts', 0)}")
        print(f"  â€¢ å¹³å‡æ¯ç¯‡è®ºæ–‡æ¦‚å¿µæ•°: {concept_stats.get('avg_concepts_per_paper', 0)}")
        
        if concept_stats.get('top_cited_papers'):
            print("\nğŸ“ˆ é«˜å¼•ç”¨è®ºæ–‡:")
            for paper in concept_stats['top_cited_papers'][:3]:
                print(f"  â€¢ {paper['title'][:50]}... (å¼•ç”¨æ•°: {paper['citation_count']})")
                
    except Exception as e:
        print(f"âš ï¸ è·å–æ¦‚å¿µæ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")
    
    print("\nğŸ¯ ç³»ç»ŸçŠ¶æ€æ€»è§ˆå®Œæˆï¼")


def paper_process(): 
    print("è®ºæ–‡å¤„ç†æµç¨‹")
    print("å®Œæ•´æµç¨‹ï¼šPDFè§£æ â†’ æ•°æ®åº“å­˜å‚¨ â†’ å‘é‡å­˜å‚¨")
    print("=" * 60)
    
    # 0. ä¸‹è½½é¢„å®šä¹‰è®ºæ–‡åˆ—è¡¨
    download_result = download_predefined_papers()
    
    if download_result["success"] > 0 or download_result["exists"] > 0:
        print(f"âœ… è®ºæ–‡ä¸‹è½½å®Œæˆï¼æ–°ä¸‹è½½: {download_result['success']}, å·²å­˜åœ¨: {download_result['exists']}")
    else:
        print("âš ï¸ æ²¡æœ‰æˆåŠŸä¸‹è½½æ–°è®ºæ–‡ï¼Œç»§ç»­å¤„ç†ç°æœ‰æ–‡ä»¶...")
    
    # 1. è·å–æ‰€æœ‰PDFæ–‡ä»¶
    paper_files = get_paper_files()
    
    if not paper_files:
        print("âš ï¸ æœªæ‰¾åˆ°PDFæ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
        return
    
    # 2. æ˜¾ç¤ºå¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
    print("\nğŸ“‹ å¾…å¤„ç†è®ºæ–‡åˆ—è¡¨:")
    for i, paper_path in enumerate(paper_files, 1):
        print(f"  {i}. {os.path.basename(paper_path)}")
    
    # 3. è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    try:
        confirm = input(f"\nâ“ ç¡®è®¤å¤„ç†è¿™ {len(paper_files)} ä¸ªæ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
        if confirm not in ['y', 'yes', 'Y', 'æ˜¯']:
            print("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œï¼Œç¨‹åºé€€å‡º")
            return
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œç¨‹åºé€€å‡º")
        return
    
    # 4. æ‰¹é‡å¤„ç†è®ºæ–‡
    results = process_papers_batch(paper_files)
    
    # 6. æ˜¾ç¤ºå¤„ç†ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æ‰¹é‡å¤„ç†ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"âœ… æˆåŠŸå¤„ç†: {results['success']} ç¯‡")
    print(f"â­ï¸ å·²è·³è¿‡: {results['skipped']} ç¯‡")
    print(f"âŒ å¤„ç†å¤±è´¥: {results['failed']} ç¯‡")
    print(f"ğŸ“ æ€»è®¡: {results['total']} ç¯‡")
    
    # æ˜¾ç¤ºè·³è¿‡çš„æ–‡ä»¶è¯¦æƒ…
    if results['skipped'] > 0:
        print(f"\nâ­ï¸ è·³è¿‡çš„æ–‡ä»¶è¯¦æƒ…:")
        for detail in results['details']:
            if detail['status'] == 'skipped':
                print(f"  - {os.path.basename(detail['file'])}: {detail['message']}")
    
    # 7. æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶è¯¦æƒ…
    if results['failed'] > 0:
        print(f"\nâŒ å¤±è´¥æ–‡ä»¶è¯¦æƒ…:")
        for detail in results['details']:
            if detail['status'] == 'failed':
                print(f"  - {os.path.basename(detail['file'])}: {detail['message']}")
    
    # 8. æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    if results['success'] > 0:
        show_final_stats()
    
    
    print("\nğŸ‰ è®ºæ–‡æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print("ğŸ’¡ æç¤º: ç°åœ¨å¯ä»¥é€šè¿‡å‘é‡æœç´¢åŠŸèƒ½æŸ¥æ‰¾ç›¸å…³è®ºæ–‡äº†")

# def question_generate():
#         # è®¾è®¡prompt
#         return []

def main():
    """ä¸»å‡½æ•°"""
    #è®ºæ–‡å¤„ç†
    paper_process()
    # #é¢˜ç›®ç”Ÿæˆ
    # question_generate()

if __name__ == "__main__":
    main()
    